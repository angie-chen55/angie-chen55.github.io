<p align="center">
  <a href="#papers">Selected Papers</a> | <a href="#talks">Invited Talks</a>
</p>
Hi! I'm a PhD student at NYU Center for Data Science in the [Machine Learning for Language](https://wp.nyu.edu/ml2/) group, advised by [Kyunghyun Cho](https://kyunghyuncho.me/). I'm primarily interested in deep learning models for language, especially <b>learning from rich feedback</b> (*e.g.* [natural language](https://arxiv.org/abs/2303.16749) [feedback](https://arxiv.org/abs/2204.14146) and [interactions with the environment](https://arxiv.org/abs/2302.14838)) and <b>[understanding](https://arxiv.org/abs/2309.07311) + [evaluating](https://arxiv.org/abs/2110.08193) how large language models (LLMs) learn</b>. Recently, I've also become interested in the use of <b>LLMs for biological applications</b>.

I have worked as a student researcher at Google Research on [streaming models for disfluency detection](https://arxiv.org/abs/2205.00620) and at Google Brain on [LMs for neural architecture search (NAS)](https://arxiv.org/abs/2302.14838). Prior to NYU, I worked as a SWE at Google and graduated with high honors from Princeton Computer Science. [Sebastian Seung](https://www.cs.princeton.edu/people/profile/sseung) advised my senior thesis at Princeton, for which I received an Outstanding Computer Science Thesis award.

Outside of my research, I enjoy running, baking more pastries than I can feasibly eat, and cooking. I also volunteer as a rape and domestic violence crisis counselor/victim advocate for the [NYC Crime Victims Treatment Center](https://www.cvtcnyc.org/) (at Lenox Health Greenwich Village and Brookdale Hospital) and a crisis counselor for [Crisis Text Line](https://www.crisistextline.org/).

<h2 align="center" id="papers">
  Selected Papers
</h2>

* * *

My work is largely split into three general directions -- understanding LLM training, improving how LLMs learn from feedback, and evaluating LLMs. For a more complete list of my past work, please see my <a href="https://www.semanticscholar.org/author/Angelica-Chen/13336152">Semantic Scholar profile</a>. <br>

<h3>Understanding LLM Training</h3>
<b><u>Preference Learning Algorithms Do Not Learn Preference Rankings</u></b><br>
<i>Preprint</i><br>
<b>Chen, Angelica</b>, Sadhika Malladi, Lily H. Zhang, Xinyi Chen, Qiuyi Zhang, Rajesh Ranganath, Kyunghyun Cho.<br>
[<a href="https://github.com/angie-chen55/pref-learning-ranking-acc/blob/main/pref_learning_algs_do_not_learn_pref_rankings.pdf">Preprint</a>] [<a href="https://github.com/angie-chen55/pref-learning-ranking-acc/tree/main">GitHub</a>] <br>
<br>
<b><u>Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs</u></b><br>
<i>ICLR 2024 (Spotlight)</i><br>
<b>Chen, Angelica</b>, Ravid Shwartz-Ziv, Kyunghyun Cho, Matthew L. Leavitt, Naomi Saphra.<br>
[<a href="https://openreview.net/forum?id=MO5PiKHELW">OpenReview</a>] [<a href="https://arxiv.org/abs/2309.07311">Arxiv</a>] <br>
<br>
<b><u>Latent State Models of Training Dynamics</u></b><br>
<i>Transactions on Machine Learning Research</i><br>
Michael Y. Hu, <b>Angelica Chen</b>, Naomi Saphra, Kyunghyun Cho<br>
[<a href="https://arxiv.org/abs/2308.09543">Arxiv</a>] [<a href="https://openreview.net/forum?id=NE2xXWo0LF&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DTMLR%2FAuthors%23your-submissions)">OpenReview</a>]<br>
<br>

<h3>Improving How LLMs Learn From Feedback</h3>
<b><u>Playing Large Games with Oracles and AI Debate</u></b><br>
<i>Preprint</i><br>
Xinyi Chen, <b>Angelica Chen</b>, Dean Foster, Elad Hazan.<br>
[<a href="https://arxiv.org/abs/2312.04792">Arxiv</a>] [<a href="https://github.com/angie-chen55/alignment-game-public">GitHub</a>] <br>
<br>
<b><u>EvoPrompting: Language Models for Code-Level Neural Architecture Search</u></b><br>
<i>NeurIPS 2023 (poster)</i><br>
<b>Chen, Angelica</b>, David M. Dohan and David R. So<br>
[<a href="https://openreview.net/forum?id=ifbF4WdT8f">OpenReview</a>] [<a href="https://arxiv.org/abs/2302.14838">Arxiv</a>]<br>
<br>
<b><u>Learning from Natural Language Feedback</u></b><br>
<i>Transactions on Machine Learning Research</i><br>
<b>Chen, Angelica<sup>\*</sup></b>, Jérémy Scheurer<sup>\*</sup>, Tomasz Korbak, Jon Ander Campos, Jun Shern Chan, Samuel R. Bowman, Kyunghyun Cho, Ethan Perez<br>
[<a href="https://openreview.net/forum?id=xo3hI5MwvU">OpenReview</a>] [<a href="https://github.com/nyu-mll/ILF-for-code-generation">GitHub</a>]<br>
<br>
<b><u>Pretraining Language Models with Human Preferences</u></b><br>
<i>ICML 2023 (oral)</i><br>
Korbak, Tomasz, Kejian Shi, <b>Angelica Chen</b>, Rasika Bhalerao, Christopher L. Buckley, Jason Phang, Sam Bowman and Ethan Perez<br>
[<a href="https://arxiv.org/abs/2302.08582.pdf">Arxiv</a>]<br>
<br>
<b><u>Teaching BERT to Wait: Balancing Accuracy and Latency for Streaming Disfluency Detection</u></b><br>
<i>NAACL 2022 (oral)</i><br>
<b>Chen, Angelica</b>, Victoria Zayats, Daniel David Walker and Dirk Ryan Padfield<br>
[<a href="https://www.aclanthology.org/2022.naacl-main.60.pdf">ACL Anthology</a>]<br>
<br>

<h3>Evaluating LLMs</h3>
<b><u>Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs</u></b><br>
<i>Transactions on Machine Learning Research</i><br>
<b>Chen, Angelica</b>, Jason Phang, Alicia Parrish, Vishakh Padmakumar, Chen Zhao, Samuel R. Bowman, Kyunghyun Cho.<br> 
[<a href="https://arxiv.org/abs/2305.14279">Arxiv</a>] [<a href="https://openreview.net/forum?id=5nBqY1y96B">OpenReview</a>]<br>
<br>
<b><u>QuALITY: Question Answering with Long Input Texts, Yes!</u></b><br>
<i>NAACL 2022</i><br>
Richard Yuanzhe Pang, Alicia Parrish, Nitish Joshi, Nikita Nangia, Jason Phang, <b>Angelica Chen</b>, Vishakh Padmakumar, Johnny Ma, Jana Thompson, He He, Samuel Bowman<br>
[<a href="https://aclanthology.org/2022.naacl-main.391/">ACL Anthology</a>]<br>
<br>
<b><u>BBQ: A hand-built bias benchmark for question answering</u></b><br>
<i>ACL Findings 2022</i><br>
Parrish, Alicia, <b>Angelica Chen</b>, Nikita Nangia, Vishakh Padmakumar, Jason Phang, Jana Thompson, Phu Mon Htut and Sam Bowman<br>
[<a href="https://aclanthology.org/2022.findings-acl.165/">ACL Anthology</a>]<br>

<h2 align="center" id="talks">
  Invited Talks
</h2>

* * *

*   "Interpreting Model Training," <i>Princeton Language and Intelligence</i>, April 18, 2024 (<a href="https://docs.google.com/presentation/d/1zyjPLBF1RyGCIxWPs_G81YdXAP2rgaCFksraiUZSDr0/edit?usp=sharing">Slides</a>)
*   "Learning From Natural Language Feedback," <i>Cohere</i>, August 2, 2023 (<a href="https://www.youtube.com/watch?v=Ex2qCbZCIFI">Video</a>)
*   "Learning From Natural Language Feedback," <i>Mosaic ML</i>, April 16, 2023
*   "Teaching BERT To Wait," <i>NYU Natural Language Understanding DS-GA 1012/LING-GA 1012</i>, March 10, 2022 (<a href="https://docs.google.com/presentation/d/1kDJU-Ar03UWzeXlu4RzF04tFXc6v2ei6GV6VYqLvPus/edit?usp=sharing">Slides</a>)
